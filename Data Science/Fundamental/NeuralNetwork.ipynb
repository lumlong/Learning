{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_onehot(y):\n",
    "    \n",
    "    n_classes = len(np.unique(y))\n",
    "    n_samples = len(y)\n",
    "    \n",
    "    y_onehot = np.zeros([n_samples, n_classes])\n",
    "    for i, val in enumerate(y):\n",
    "        y_onehot[i, val] = 1\n",
    "    return y_onehot\n",
    "\n",
    "\n",
    "digits = load_digits(n_class=6)\n",
    "\n",
    "X, y = digits.data, digits.target\n",
    "y_onehot = get_onehot(y)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "n_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_hid0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[43m_hid0\u001b[49m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(axs\u001b[38;5;241m.\u001b[39mravel()):\n\u001b[1;32m      5\u001b[0m     ax\u001b[38;5;241m.\u001b[39mimshow(X[idx]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m)), cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mbinary)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_hid0' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=10, ncols=_hid0, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(X[idx].reshape((8, 8)), cmap=plt.cm.binary)\n",
    "    ax.axis(\"off\")\n",
    "_ = fig.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 28\n",
    "rnd = np.random.RandomState(rand_seed)\n",
    "\n",
    "# Hidden layer\n",
    "n_node_h = 50\n",
    "weight_h = rnd.uniform(0, _hid, [n_node_h, n_features])\n",
    "bias_h = 1\n",
    "\n",
    "n_node_out = n_classes\n",
    "weight_out = rnd.random([n_node_out, n_node_h])\n",
    "bias_out = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1083, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_h = X.dot(weight_h.T) + bias_h\n",
    "z_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1083, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_h = 1 / (1 + np.exp(-z_h))\n",
    "a_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1083, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_out = a_h.dot(weight_out.T) + bias_out\n",
    "a_out = 1 / (1 + np.exp(-z_out))\n",
    "a_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss_out = (y_onehot * np.log(a_out)) + ((1 - y_onehot) * np.log(1 - a_out))\n",
    "avg_logloss_out = np.average(logloss_out, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weight_out = np.average(avg_logloss_out * a_out, axis=0)\n",
    "new_bias_out = np.average(avg_logloss_out * bias_out, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_out = weight_out - new_weight_out.reshape([6,1])\n",
    "bias_out = bias_out - new_bias_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, X, y, n_node_hid, learning_rate=0.1) -> None:\n",
    "        rand_seed = 28\n",
    "        self.rnd = np.random.RandomState(rand_seed)\n",
    "        \n",
    "        self.n_node_hid = n_node_hid\n",
    "        self.n_samples, self.n_features  = X.shape\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.n_node_out = n_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights and biases with random values\n",
    "        self.W_hid = rnd.uniform(0, 1, [n_features, n_node_hid])\n",
    "        self.b_hid = np.zeros((1, n_node_hid))\n",
    "\n",
    "        self.W_out = rnd.random([n_node_hid, n_node_out])\n",
    "        self.b_out = np.zeros((1, n_node_out))\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "\n",
    "        \n",
    "    def feedforward(self, X):\n",
    "        \n",
    "        self.z_hid = np.dot(X, self.W_hid) + self.b_hid #[1xxx, 64][64, 50] -> [1000, 50]\n",
    "        self.a_hid = self.sigmoid(self.z_hid)\n",
    "        \n",
    "        self.z_out = np.dot(self.a_hid, self.W_out) + self.b_out\n",
    "        self.a_out = self.sigmoid(self.z_out)\n",
    "        \n",
    "        return self.a_out\n",
    "\n",
    "\n",
    "    def backpropagation(self, X, y):\n",
    "        # Calculate error and gradients\n",
    "        delta_out = (self.a_out - y) * self.sigmoid_derivative(self.z_out)\n",
    "        dW_out = np.dot(self.a_hid.T, delta_out)\n",
    "        db_out = np.sum(delta_out, axis=0, keepdims=True)\n",
    "        \n",
    "        delta_hid = np.dot(delta_out, self.W_out.T) * self.sigmoid_derivative(self.z_hid)\n",
    "        dW_hid = np.dot(X.T, delta_hid)\n",
    "        db_hid = np.sum(delta_hid, axis=0, keepdims=True)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.W_out -= self.learning_rate * dW_out\n",
    "        self.b_out -= self.learning_rate * db_out\n",
    "        self.W_hid -= self.learning_rate * dW_hid\n",
    "        self.b_hid -= self.learning_rate * db_hid\n",
    "    \n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            self.feedforward(X)\n",
    "            self.backpropagation(X, y)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}: Loss = {self.calculate_loss(X, y)}\")\n",
    "\n",
    "\n",
    "    def calculate_loss(self, X, y):\n",
    "        return np.mean(np.square(self.feedforward(X) - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1083,6) (1083,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(X, y, \u001b[38;5;241m50\u001b[39m, learning_rate)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train the neural network\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfeedforward(X)\n",
      "Cell \u001b[0;32mIn[50], line 60\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeedforward(X)\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackpropagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_loss(X,\u001b[38;5;250m \u001b[39my)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[50], line 42\u001b[0m, in \u001b[0;36mNeuralNetwork.backpropagation\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackpropagation\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Calculate error and gradients\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     delta_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid_derivative(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_out)\n\u001b[1;32m     43\u001b[0m     dW_out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_hid\u001b[38;5;241m.\u001b[39mT, delta_out)\n\u001b[1;32m     44\u001b[0m     db_out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(delta_out, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1083,6) (1083,) "
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "# Create a neural network\n",
    "nn = NeuralNetwork(X, y, 50, learning_rate)\n",
    "\n",
    "# Train the neural network\n",
    "nn.train(X, y, epochs)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nn.feedforward(X)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataeng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
